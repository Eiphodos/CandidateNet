{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import monai\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from matplotlib.colors import ListedColormap\n",
    "from einops import rearrange\n",
    "from oracle.models.transformer_encoder import VisionTransformer\n",
    "from oracle.models.transformer_decoder import SegmentationTransformer\n",
    "from oracle.models.transformer_segmenter import MultiResSegmenter\n",
    "from oracle.image_utils import convert_1d_index_to_2d, convert_scale_to_coords_in_full_res, convert_1d_patched_index_to_2d_org_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf7436cb674e3f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T08:26:47.922432755Z",
     "start_time": "2024-10-16T14:29:24.788623Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe1c392d4b4dc25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T08:26:47.962964050Z",
     "start_time": "2024-10-16T14:29:24.804899Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_folder = '/media/david/T7/Kvasir-SEG/train'\n",
    "val_folder = '/media/david/T7/Kvasir-SEG/validation'\n",
    "test_folder = '/media/david/T7/Kvasir-SEG/test'\n",
    "#train_folder = r'D:\\Datasets\\Kvasir-SEG\\train'\n",
    "#val_folder = r'D:\\Datasets\\Kvasir-SEG\\validation'\n",
    "#test_folder = r'D:\\Datasets\\Kvasir-SEG\\test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a1e28e3f4db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kvasir_data_to_dict(folder):\n",
    "    images = os.listdir(os.path.join(folder, 'images'))\n",
    "    data_list_dict = []\n",
    "    for i in images:\n",
    "        try:     \n",
    "            if os.path.exists(os.path.join(folder, 'masks', i)):\n",
    "                data_dict = {'image': os.path.join(folder, 'images', i),\n",
    "                             'label': os.path.join(folder, 'masks', i)}\n",
    "                data_list_dict.append(data_dict)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to find label file {} with exception {}\".format(i, e))\n",
    "    \n",
    "    return data_list_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71278943b6c42a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = kvasir_data_to_dict(train_folder)\n",
    "val_data = kvasir_data_to_dict(val_folder)\n",
    "test_data = kvasir_data_to_dict(test_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339921314d6ea69d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T08:26:47.964085556Z",
     "start_time": "2024-10-16T14:29:24.821032Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transform_list = [monai.transforms.LoadImaged(keys=['image', 'label']),\n",
    "              monai.transforms.EnsureChannelFirstD(keys=['image', \"label\"]),\n",
    "              monai.transforms.NormalizeIntensityd(keys=['image'], nonzero=True, channel_wise=True),\n",
    "              monai.transforms.ScaleIntensityRanged(keys=['label'], a_min=0, a_max=255, b_min=0, b_max=1,clip=True),\n",
    "              #monai.transforms.BorderPadd(keys=['image', 'label'], spatial_border=80),\n",
    "              monai.transforms.Resized(keys=[\"image\"], spatial_size=(512, 512), mode='bilinear'),\n",
    "              monai.transforms.Resized(keys=[\"label\"], spatial_size=(512, 512), mode='nearest'),\n",
    "              monai.transforms.ToTensord(keys=[\"image\", \"label\"])]\n",
    "transforms = monai.transforms.Compose(transform_list)\n",
    "\n",
    "train_dataset = monai.data.Dataset(train_data, transform=transforms)\n",
    "val_dataset = monai.data.Dataset(val_data, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5213be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_val = monai.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    "    persistent_workers=False\n",
    "    )\n",
    "\n",
    "data_loader_train = monai.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    "    persistent_workers=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ced5a7d235732",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T08:26:47.965374987Z",
     "start_time": "2024-10-16T14:29:31.830019Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e998be46bef3b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T08:26:47.965773943Z",
     "start_time": "2024-10-16T14:29:31.846740Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualize_data(im, lab):\n",
    "    plt.figure()\n",
    "    if im is not None:\n",
    "        if im.shape[0] < 4:\n",
    "            im = im.permute(1, 2, 0)\n",
    "        plt.imshow(im.squeeze().cpu().numpy())\n",
    "        plt.imshow(lab.squeeze().cpu().numpy(), interpolation='none', alpha=0.33)\n",
    "    else:\n",
    "        plt.imshow(lab.squeeze().cpu().numpy(), interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db73b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_patches_scale(patches_scale_coords, n_scales, initial_patch_size, image_size, org_image=None, labels=None):\n",
    "    colormap = ListedColormap(['silver', 'chocolate', 'blue', 'green', 'orange', 'magenta', 'red', 'lime'])\n",
    "    full_image = torch.zeros(image_size[0] * image_size[1])\n",
    "    for scale in range(n_scales):\n",
    "        patch_size = initial_patch_size // 2**scale\n",
    "        indx_curr_scale = patches_scale_coords[:, 0] == scale\n",
    "        coords_at_curr_scale = patches_scale_coords[indx_curr_scale, 1]\n",
    "        coords_at_org_scale = convert_scale_to_coords_in_full_res(coords_at_curr_scale, patch_size, image_size[0])\n",
    "        full_image[coords_at_org_scale] = scale\n",
    "    full_image = full_image.view(image_size[0], image_size[1])\n",
    "    if org_image is not None:\n",
    "        plt.imshow(org_image.squeeze().cpu().numpy(), cmap='gray')\n",
    "    if labels is not None:\n",
    "        plt.imshow(labels.squeeze().cpu().numpy(), interpolation='none', alpha=0.33)\n",
    "    plt.imshow(full_image.squeeze().cpu().numpy(), interpolation='none', alpha=0.9, cmap=colormap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef18f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = data_loader_train.dataset.__getitem__(246)\n",
    "example_inputs = out['image']\n",
    "example_labels = out['label']\n",
    "example_inputs = example_inputs.to(device, non_blocking=True)\n",
    "example_labels = example_labels.to(device, non_blocking=True)\n",
    "print(example_inputs.shape)\n",
    "visualize_data(example_inputs, example_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27f9e72e93eb364",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T08:26:47.998464014Z",
     "start_time": "2024-10-16T14:29:32.080635Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_oracle_labels(labels, patch_size): \n",
    "    max = F.max_pool2d(labels.float(), patch_size, stride=patch_size).to(torch.int32)\n",
    "    min = F.max_pool2d(-labels.float(), patch_size, stride=patch_size).to(torch.int32)\n",
    "    one_class = (max == -min)\n",
    "    \n",
    "    patch_groups_per_img = one_class.to(torch.uint8)\n",
    "    \n",
    "    return patch_groups_per_img.to(torch.long).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5be1c4b357ff04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T08:26:48.000398627Z",
     "start_time": "2024-10-16T14:29:32.096674Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patch_sizes_used = [64, 32, 16, 8, 4]\n",
    "oracle_labels_multires = []\n",
    "for ps in patch_sizes_used:\n",
    "    ol = create_oracle_labels(example_labels, ps)\n",
    "    oracle_labels_multires.append(ol)\n",
    "    visualize_data(None, ol)\n",
    "    print(ol.shape)\n",
    "    #print(ol.sum())\n",
    "\n",
    "\n",
    "#oracle_labels = create_oracle_labels(labels, 64)\n",
    "#visualize_data(inputs, oracle_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fecaa714b7bfa66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T08:26:48.001486600Z",
     "start_time": "2024-10-16T14:29:32.285854Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_encoder = 64\n",
    "d_decoder = 64\n",
    "n_encoder_layers = len(patch_sizes_used)\n",
    "n_decoder_layers = 2\n",
    "patch_size = patch_sizes_used[0]\n",
    "image_size = (example_inputs.shape[1], example_inputs.shape[2])\n",
    "\n",
    "model = MultiResSegmenter(image_size=image_size,\n",
    "                          patch_size=patch_size,\n",
    "                          channels=3,\n",
    "                          n_layers_encoder=n_encoder_layers,\n",
    "                          d_encoder=d_encoder,\n",
    "                          d_ff_encoder=d_encoder*4,\n",
    "                          n_heads_encoder=4,\n",
    "                          n_layers_decoder=n_decoder_layers,\n",
    "                          d_decoder=d_decoder,\n",
    "                          d_ff_decoder=d_decoder*4,\n",
    "                          n_heads_decoder=4,\n",
    "                          n_scales=len(patch_sizes_used),\n",
    "                          n_cls=2)\n",
    "\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "print(\"Total parameters: {}\".format(count_parameters(model)))\n",
    "print(\"Encoder parameters: {}\".format(count_parameters(model.encoder)))\n",
    "print(\"Decoder parameters: {}\".format(count_parameters(model.decoder)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f6b740e16daf7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T08:26:48.003090909Z",
     "start_time": "2024-10-16T14:29:32.303400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = monai.losses.DiceCELoss(to_onehot_y=True, softmax=True, squared_pred=False)\n",
    "post_label = monai.transforms.AsDiscrete(to_onehot=2)\n",
    "post_pred = monai.transforms.AsDiscrete(argmax=True, to_onehot=2)\n",
    "dice_metric = monai.metrics.DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=True)\n",
    "dice_metric_val = monai.metrics.DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=True)\n",
    "epochs = 20\n",
    "total_prints = 20\n",
    "print_every_n_epochs = epochs // total_prints\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _, enc_out, _ = model(example_inputs.unsqueeze(0).to(device), oracle_labels_multires)\n",
    "    print(\"Number of tokens after encoder: {}\".format(enc_out.shape[1]))\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "    epoch_start = time.time()\n",
    "    for i, batch in enumerate(data_loader_train):\n",
    "        batch_start = time.time()\n",
    "        inputs, labels = (batch[\"image\"], batch[\"label\"])\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        oracle_labels_multires = []\n",
    "        for ps in patch_sizes_used:\n",
    "            ol = create_oracle_labels(labels, ps)\n",
    "            oracle_labels_multires.append(ol.squeeze())\n",
    "        outputs, _, patches_scale_coords = model(inputs, oracle_labels_multires)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        labels_convert = [post_label(labels[0])]\n",
    "        output_convert = [post_pred(outputs[0])]\n",
    "        dice_metric(y_pred=output_convert, y=labels_convert)\n",
    "        batch_time = time.time() - batch_start\n",
    "    dice_scores, dice_not_nans = dice_metric.aggregate()\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    if ((e + 1) % print_every_n_epochs) == 0:\n",
    "        print(\"Train Epoch: {}, Dice score: {:.4f}, loss: {:.4f}, lr: {:.4f}, epoch_time: {:.4f}\".format(e, dice_scores.item(), loss.item(), scheduler.get_last_lr()[0], epoch_time))\n",
    "        #pred = torch.argmax(outputs, dim=1)\n",
    "        #visualize_data(inputs, pred)\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(data_loader_val):\n",
    "                inputs, labels = (batch[\"image\"], batch[\"label\"])\n",
    "                inputs = inputs.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "                oracle_labels_multires = []\n",
    "                for ps in patch_sizes_used:\n",
    "                    ol = create_oracle_labels(labels, ps)\n",
    "                    oracle_labels_multires.append(ol.squeeze())\n",
    "                outputs, _, patches_scale_coords = model(inputs, oracle_labels_multires)\n",
    "                labels_convert = [post_label(labels[0])]\n",
    "                output_convert = [post_pred(outputs[0])]\n",
    "                dice_metric_val(y_pred=output_convert, y=labels_convert)\n",
    "            dice_scores_val, dice_not_nans_val = dice_metric_val.aggregate()\n",
    "            print(\"Validation - Dice score: {:.4f}\".format(dice_scores_val.item()))\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebc5335",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_patches_scale(patches_scale_coords, n_encoder_layers, patch_size, image_size, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0119dab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4afe561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CandidateNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
